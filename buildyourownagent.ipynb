{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/todd-flanagan/buildyourownagent/blob/main/buildyourownagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "# You will also want to add some sample files to the \"Files\" (folder icon)\n",
        "# on the left. When the agent asks you what to do, start with something\n",
        "# simplie like \"tell me what files are in this directory\"\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "k4z1HCMNWWD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!!git clone https://github.com/todd-flanagan/buildyourownagent.git"
      ],
      "metadata": {
        "id": "nPpIhPERIjSp",
        "outputId": "c4f0864f-8192-4aaf-f242-744b0e16f8a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Cloning into 'buildyourownagent'...\",\n",
              " 'remote: Enumerating objects: 16, done.\\x1b[K',\n",
              " 'remote: Counting objects:   6% (1/16)\\x1b[K',\n",
              " 'remote: Counting objects:  12% (2/16)\\x1b[K',\n",
              " 'remote: Counting objects:  18% (3/16)\\x1b[K',\n",
              " 'remote: Counting objects:  25% (4/16)\\x1b[K',\n",
              " 'remote: Counting objects:  31% (5/16)\\x1b[K',\n",
              " 'remote: Counting objects:  37% (6/16)\\x1b[K',\n",
              " 'remote: Counting objects:  43% (7/16)\\x1b[K',\n",
              " 'remote: Counting objects:  50% (8/16)\\x1b[K',\n",
              " 'remote: Counting objects:  56% (9/16)\\x1b[K',\n",
              " 'remote: Counting objects:  62% (10/16)\\x1b[K',\n",
              " 'remote: Counting objects:  68% (11/16)\\x1b[K',\n",
              " 'remote: Counting objects:  75% (12/16)\\x1b[K',\n",
              " 'remote: Counting objects:  81% (13/16)\\x1b[K',\n",
              " 'remote: Counting objects:  87% (14/16)\\x1b[K',\n",
              " 'remote: Counting objects:  93% (15/16)\\x1b[K',\n",
              " 'remote: Counting objects: 100% (16/16)\\x1b[K',\n",
              " 'remote: Counting objects: 100% (16/16), done.\\x1b[K',\n",
              " 'remote: Compressing objects:   7% (1/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  15% (2/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  23% (3/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  30% (4/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  38% (5/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  46% (6/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  53% (7/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  61% (8/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  69% (9/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  76% (10/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  84% (11/13)\\x1b[K',\n",
              " 'remote: Compressing objects:  92% (12/13)\\x1b[K',\n",
              " 'remote: Compressing objects: 100% (13/13)\\x1b[K',\n",
              " 'remote: Compressing objects: 100% (13/13), done.\\x1b[K',\n",
              " 'remote: Total 16 (delta 1), reused 11 (delta 1), pack-reused 0 (from 0)\\x1b[K',\n",
              " 'Receiving objects:   6% (1/16)',\n",
              " 'Receiving objects:  12% (2/16)',\n",
              " 'Receiving objects:  18% (3/16)',\n",
              " 'Receiving objects:  25% (4/16)',\n",
              " 'Receiving objects:  31% (5/16)',\n",
              " 'Receiving objects:  37% (6/16)',\n",
              " 'Receiving objects:  43% (7/16)',\n",
              " 'Receiving objects:  50% (8/16)',\n",
              " 'Receiving objects:  56% (9/16)',\n",
              " 'Receiving objects:  62% (10/16)',\n",
              " 'Receiving objects:  68% (11/16)',\n",
              " 'Receiving objects:  75% (12/16)',\n",
              " 'Receiving objects:  81% (13/16)',\n",
              " 'Receiving objects:  87% (14/16)',\n",
              " 'Receiving objects:  93% (15/16)',\n",
              " 'Receiving objects: 100% (16/16)',\n",
              " 'Receiving objects: 100% (16/16), 7.50 KiB | 3.75 MiB/s, done.',\n",
              " 'Resolving deltas:   0% (0/1)',\n",
              " 'Resolving deltas: 100% (1/1)',\n",
              " 'Resolving deltas: 100% (1/1), done.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get a response.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\"srs\")\n",
        "\n",
        "def create_file(file_name : str) -> None:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    with open(file_name, \"w\") as file:\n",
        "        file.write(\"\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(\"buildyourownagent/srs/\" + file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def write_results(file_name: str, results: str) -> None:\n",
        "    \"\"\"Write results to a file.\"\"\"\n",
        "    with open(file_name, \"a\") as file:\n",
        "        file.write(results + \"\\n\")\n",
        "\n",
        "def terminate(message: str) -> None:\n",
        "    \"\"\"Terminate the agent loop.\"\"\"\n",
        "    print(f\"Termination message: {message}\")\n",
        "\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file,\n",
        "    \"write_results\": write_results,\n",
        "    \"create_file\": create_file,\n",
        "    \"terminate\" : terminate\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of service request files.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"create_file\",\n",
        "            \"description\": \"Creates a new file of the given name.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"write_results\",\n",
        "            \"description\": \"writes a string to a file\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"file_name\": {\"type\": \"string\"},\n",
        "                    \"results\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                \"required\": [\"file_name\", \"str\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"terminate\",\n",
        "            \"description\": \"Terminates the conversation. No further actions or interactions are possible after this. Prints the provided message for the user.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"message\": {\"type\": \"string\"},\n",
        "                },\n",
        "                \"required\": [\"message\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# Define system instructions (Agent Rules)\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "retreive the list of service request files.  read each file.  If the file is not in english, transtanslate it to english.  for each file, suggest a list of 2-3 tags to categorize the request, an assessment of where it is in the workflow,\n",
        "and an issue type.  Then append the list of tags to out.txt in the form of <srfilebane> : <deploment step> : <issue type> : <tag1>, <tag2>...\n",
        "where deployment step represents the step in the deployment process the customer experienced the issue.  valid deployment steps are environment configuration, execution time, compile and package, cannot enter the workflow.\n",
        "Valid issue types are: request, howto, inquiry, issue.\n",
        "Valid tags are: CLI, installer, app designer, creash, code signing, ctf, docker, deploytool, driver code, mcc flags, mcr, path management, security, simulink, customization\n",
        "before writing the results, create a new, blank file\n",
        "write the results as you process each file\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 20\n",
        "\n",
        "user_task = \"process the srs\"\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    print(memory)\n",
        "    messages = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = completion(model=\"openai/gpt-4o\",\n",
        "                          messages = messages,\n",
        "                          tools = tools,\n",
        "                          max_tokens = 1024)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    #action = parse_action(response)\n",
        "    #print(f\"Agent action: {action}\")\n",
        "\n",
        "    # 4. Execute action\n",
        "    #result = \"Action executed\"\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "      tool = response.choices[0].message.tool_calls[0]\n",
        "      tool_name = tool.function.name\n",
        "      tool_args = json.loads(tool.function.arguments)\n",
        "      action = {\"tool_name\": tool_name, \"args\": tool_args}\n",
        "\n",
        "      if tool_name == \"terminate\":\n",
        "        print(terminate(action[\"args\"][\"message\"]))\n",
        "        break\n",
        "      elif tool_name in tool_functions:\n",
        "        try:\n",
        "          result = {\"result\": tool_functions[tool_name](**tool_args)}\n",
        "        except Exception as e:\n",
        "          result = {\"error\": str(f\"Error executing {tool_name}: {e}\")}\n",
        "      else:\n",
        "          result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "      print(f\"Executing: {tool_name} with args {tool_args}\")\n",
        "      print(f\"Action result: {result}\")\n",
        "\n",
        "      # 5. Update memory with response and results\n",
        "      memory.extend([\n",
        "          {\"role\": \"assistant\", \"content\": json.dumps(action)},\n",
        "          {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "      ])\n",
        "    else:\n",
        "      result = response.choices[0].message.content\n",
        "      print(f\"Action result: {result}\")\n",
        "\n",
        "    iterations += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8CAlD1XWjPa",
        "outputId": "0a2f1ac5-4c64-4c2c-8372-c654c538ffaf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'process the srs'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CLricAGVwF4lkZU0jVOL3jnZCgYdM', created=1759327418, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_lrHhgEbcBIJtVwMHRfOPgPgD', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=417, total_tokens=427, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Executing: list_files with args {}\n",
            "Action result: {'error': \"Error executing list_files: [Errno 2] No such file or directory: 'srs'\"}\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CLridz6LPGrc2VQWXDU4mDLvkaGNs', created=1759327419, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"It seems that there was an error retrieving the list of service request files from the specified directory. Let's try to address this by ensuring we access the correct directory or path where the service request files are stored. Would you like to specify a different directory or provide additional details?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=55, prompt_tokens=464, total_tokens=519, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Action result: It seems that there was an error retrieving the list of service request files from the specified directory. Let's try to address this by ensuring we access the correct directory or path where the service request files are stored. Would you like to specify a different directory or provide additional details?\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CLrigQoFJK09iZi7ov99uoRQNrDvD', created=1759327422, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_NsPnWNHfJH3GqpTn37KRdFZw', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=464, total_tokens=474, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Executing: list_files with args {}\n",
            "Action result: {'error': \"Error executing list_files: [Errno 2] No such file or directory: 'srs'\"}\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CLrihnAespROpddehGbG277bCbv4B', created=1759327423, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_E0bKYeQnS2HF1N9Flj6cihjC', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=511, total_tokens=521, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Executing: list_files with args {}\n",
            "Action result: {'error': \"Error executing list_files: [Errno 2] No such file or directory: 'srs'\"}\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CLrijBTn3Qj5IwcNYlwtW79wZrvot', created=1759327425, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"message\":\"It seems there is an issue accessing the service request files. Please ensure that the files are available in the correct directory and try again.\"}', name='terminate'), id='call_DxZHhyFFlDoqtkt901qd6nYi', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=40, prompt_tokens=558, total_tokens=598, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Termination message: It seems there is an issue accessing the service request files. Please ensure that the files are available in the correct directory and try again.\n",
            "None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}