{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/todd-flanagan/buildyourownagent/blob/main/buildyourownagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4z1HCMNWWD-"
      },
      "outputs": [],
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "# You will also want to add some sample files to the \"Files\" (folder icon)\n",
        "# on the left. When the agent asks you what to do, start with something\n",
        "# simplie like \"tell me what files are in this directory\"\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8CAlD1XWjPa",
        "outputId": "be46f5f6-6b5f-474d-8113-07aea3cb60cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'user', 'content': 'process the srs'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CJQ8LdWhBP3TdqdIcDlgpRpjF63H3', created=1758744725, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_f33640a400', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_5aIlht1n2GZ0smWUTI4KMmLE', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=419, total_tokens=429, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Executing: list_files with args {}\n",
            "Action result: {'error': \"Error executing list_files: [Errno 2] No such file or directory: 'srs'\"}\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CJQ8NUvbL52G2qj4V59cVDKydAAxQ', created=1758744727, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_f33640a400', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_1qzYSkTY3uAuBIjc8UGiVjQ7', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=466, total_tokens=476, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Executing: list_files with args {}\n",
            "Action result: {'error': \"Error executing list_files: [Errno 2] No such file or directory: 'srs'\"}\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CJQ8QRHnsWyUcj2UDJoaDRjcp3EB1', created=1758744730, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_f33640a400', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_0ZhDiDgUNZyvfAuJQrAyJqgg', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=513, total_tokens=523, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Executing: list_files with args {}\n",
            "Action result: {'error': \"Error executing list_files: [Errno 2] No such file or directory: 'srs'\"}\n",
            "[{'role': 'user', 'content': 'process the srs'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}, {'role': 'assistant', 'content': '{\"tool_name\": \"list_files\", \"args\": {}}'}, {'role': 'user', 'content': '{\"error\": \"Error executing list_files: [Errno 2] No such file or directory: \\'srs\\'\"}'}]\n",
            "Agent thinking...\n",
            "Agent response: ModelResponse(id='chatcmpl-CJQ8RIyEevSt58v6zqLOI9oqq5QZE', created=1758744731, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_f33640a400', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"message\":\"It seems there was an error accessing the directory for service request files. Please ensure that the directory exists or is correctly specified.\"}', name='terminate'), id='call_nBBTfkV6AP2ch5YPLJNvSzyG', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=38, prompt_tokens=560, total_tokens=598, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
            "Termination message: It seems there was an error accessing the directory for service request files. Please ensure that the directory exists or is correctly specified.\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get a response.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "def list_sr_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\"srs\")\n",
        "\n",
        "def create_file(file_name : str) -> None:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    with open(file_name, \"w\") as file:\n",
        "        file.write(\"\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(\"srs/\" + file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def write_results(file_name: str, results: str) -> None:\n",
        "    \"\"\"Write results to a file.\"\"\"\n",
        "    with open(file_name, \"a\") as file:\n",
        "        file.write(results + \"\\n\")\n",
        "\n",
        "def terminate(message: str) -> None:\n",
        "    \"\"\"Terminate the agent loop.\"\"\"\n",
        "    print(f\"Termination message: {message}\")\n",
        "\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file,\n",
        "    \"write_results\": write_results,\n",
        "    \"create_file\": create_file,\n",
        "    \"terminate\" : terminate\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_sr_files\",\n",
        "            \"description\": \"Returns a list of service request files.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"create_file\",\n",
        "            \"description\": \"Creates a new file of the given name.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"write_results\",\n",
        "            \"description\": \"writes a string to a file\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"file_name\": {\"type\": \"string\"},\n",
        "                    \"results\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                \"required\": [\"file_name\", \"str\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"terminate\",\n",
        "            \"description\": \"Terminates the conversation. No further actions or interactions are possible after this. Prints the provided message for the user.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"message\": {\"type\": \"string\"},\n",
        "                },\n",
        "                \"required\": [\"message\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# Define system instructions (Agent Rules)\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "retreive the list of service request files from the folder buildyourownagent/srs.  read each file.  If the file is not in english, transtanslate it to english.  \n",
        "for each file, suggest a list of 2-3 tags to categorize the request, an assessment of where it is in the workflow,\n",
        "and an issue type.  Then append the list of tags to out.txt in the form of <srfilebane> : <deploment step> : <issue type> : <tag1>, <tag2>...\n",
        "where deployment step represents the step in the deployment process the customer experienced the issue.  \n",
        "the valid deployment steps are in the file buildyourownagent/agentdata/deploymentsteps.txt\n",
        "Valid issue types are: request, howto, inquiry, issue.\n",
        "The valid tags are in buildyourownagent/agentdata/tags.txt\n",
        "before writing the results, create a new, blank file\n",
        "write the results as you process each file\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 20\n",
        "\n",
        "user_task = \"process the srs\"\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    print(memory)\n",
        "    messages = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = completion(model=\"openai/gpt-4o\",\n",
        "                          messages = messages,\n",
        "                          tools = tools,\n",
        "                          max_tokens = 1024)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    #action = parse_action(response)\n",
        "    #print(f\"Agent action: {action}\")\n",
        "\n",
        "    # 4. Execute action\n",
        "    #result = \"Action executed\"\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "      tool = response.choices[0].message.tool_calls[0]\n",
        "      tool_name = tool.function.name\n",
        "      tool_args = json.loads(tool.function.arguments)\n",
        "      action = {\"tool_name\": tool_name, \"args\": tool_args}\n",
        "\n",
        "      if tool_name == \"terminate\":\n",
        "        print(terminate(action[\"args\"][\"message\"]))\n",
        "        break\n",
        "      elif tool_name in tool_functions:\n",
        "        try:\n",
        "          result = {\"result\": tool_functions[tool_name](**tool_args)}\n",
        "        except Exception as e:\n",
        "          result = {\"error\": str(f\"Error executing {tool_name}: {e}\")}\n",
        "      else:\n",
        "          result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "      print(f\"Executing: {tool_name} with args {tool_args}\")\n",
        "      print(f\"Action result: {result}\")\n",
        "\n",
        "      # 5. Update memory with response and results\n",
        "      memory.extend([\n",
        "          {\"role\": \"assistant\", \"content\": json.dumps(action)},\n",
        "          {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "      ])\n",
        "    else:\n",
        "      result = response.choices[0].message.content\n",
        "      print(f\"Action result: {result}\")\n",
        "\n",
        "    iterations += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
